Kafka
Apache Kafka is a horizontally scalable, fault-tolerant, distributed streaming platform, and it is consciously designed for building real-time streaming data architecture.
Kafka is a messaging broker. Everything else is an API, library or a framework to either interact with the Kafka broker or work with the data in real-time.
Primary Broker Responsibilities
	1)Receive messages from the producers and acknowledge the successful receipt.  
	2)Store the message in a log file to safeguard it from potential loss. 
		Storage is also critical to ensure that the consumers can consume it later, and they do not necessarily need to read it in real-time.
	3)Deliver the messages to the consumers when they request it.



1)Kafka Message Storage Architecture
	Some core concepts such as Kafka topics, logs, partitions, replication factor, segments, offsets, and offset-index.
2)Kafka CLuster Architecture
	Concepts associated with Cluster formation, Zookeeper,and the Controller.
3)Kafka Distribution Architecture
	We will tie up the other above two architectures and try to understand how the work is distributed in the Kafka cluster.
	Concepts such as Leaders, Followers, In Sync Replicas, committed and uncommitted messages.


Topics
	A topic is a particular stream of data
	A topic is identified by its name
	It supports  any kind of message format like json, text file, binary etc.
	The sequence of messages in a topic is called a data stream. And so Kafka is called data streaming platform.
	We can have as many topics as we want in Kafka Cluster
	
	A topic is like a table in database(Without all the constraints)
	We cannot query topics, instead , use Kafka Producers to send data & Kafka Consumers to read the data.
	
	Kafka Topics are Immutable-Once data is written to a partition, it cannot be changed
		We cannot delete or update data.
		But data is kept only for a limited time(default is one week-configurable)
	 
Partitions & Offsets
	Topics are split in partitions(example 100 partitions)
		Messages in each partition are ordered.
		Each message within a partition gets an incremental id , called offset or Kafka Partition Offset.
		Order is quaranteed only within a partition(not across partitions).
		Offset only have a meaning for a specific partition.
		Offset are not re-used even if previous message have been deleted.
		Data is assigned randomly to a partition unless a key is provided.
		We can have as many partition per topic as we want.
		
	The partition is the smallest unit and it is going to be sitting on a single machine.You cannot break it again
	If you want to locate a specific message, you must read 3 things. 
		Topic name, 
		Partition number 
		Offset number.

	Topic partitions are not only a solution to increase their storage capacity but also a method to distribute the workload.
	Kafka topic partitions are the core idea of making Kafka are distributed and a scalable system.

	Kafka doesn't allow more than one consumer to read and process data from the same partitions simultaneously.
		And this restriction is necessary to avoid the double reading of records.

	Apache Kafka creates a separate directory for each topic partition. 

Classification of Partition replicas
		Partition Leaders Partition 
			It will be created first
		Partition Followers Partition 

Replication Factor
	No of copies for each partition
	No of replicas=	partitions * replication


Kafka Log Segments
	Log files are split into small files , are called segment (.log files).
	By default segment size is minimum of  1 GB or 7 days data.

Kafka Message Offset
	Message in partition is identified by 64bit integer offset.
	
Kafka Message Index
	WHen consumer ask message with starting offset, offset.index will will be helpful
	Kafka also store timstamp for each message in .timeindex file.
	
	
Producers
	Producers write data to topics(topics are made of partitions)
	Producers know to which partition to write to (and which Kafka Broker has this partition)
	In case of Kafka broker failures, producers will automatically recover.
	
	Message keys
		Producers can choose to send a key with the message(string, number, binary etc...)
		If key==null then , data is sent roundrobin(partition 0 then partition 1 then partition 2...)
		If key !=null, then all messages for that key will always go to the same partition(hashing).
			A key are typically sent if we need message ordering for a speific field.
		

Kafka Messages Anatomy
	Key-binary
		Can be null
	Value-binary
		Can be null
	Compression type
		none, gzip,snappy, lz4,zstd
	Headers(Optional)
		key value pairs
	Partition+Offset
	Timestamp (system or user set)
	
	
Kafka Message Serializer
	Kafka only accepts bytes as an input from producers & send bytes out as an output to consumers.
	Message serialization means transforming objects/data into bytes.
	
	They are used on the value & the key.
		Key Object(123) ->int ->Key serializer=Integer Serializer-> bytes-> Key binary
		Value Object("Hello World!") ->string ->Value serializer=String Serializer-> bytes-> Value binary
	Kafka Producers have common Serializers.
		String (incl JSON)
		Int, FLoat
		Avro
		Protobuf
	
	
Kafka Message Key Hashing
	A Kafka producer partitioner logic is a code logic that takes a record & determines to which partition to sent it into.
	Key hashing is the process of determining the mapping of a key to a partition.
	In the default Kafka Partitioner logic , the key are hashed useing the murmer2 algorithm, 
			targetPartition=Math.abs(Utils.murmer2(keyBytes))% (numPartitions-1);
	
